{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json, os, re\n",
    "from metadata_metrics import readability_score, completeness_score_img, completeness_score_jsonxml, completeness_score_keyword, completeness_score_netcdf, completeness_score_tabular, tfidf_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import pickle as pkl"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "def get_metadata_metrics(dequeue_list, file_to_index_dict, tfidf_precomputed, threshold):\n",
    "\treadability_scores = dict()\n",
    "\tcompleteness_scores = dict()\n",
    "\ttfidf_scores = dict()\n",
    "\tcost_scores = dict()\n",
    "\textractor_count = {'keyword': 0, 'tabular':0, 'json/xml':0, 'netcdf': 0, 'image': 0}\n",
    "\tfile_count = dict()\n",
    "\tcount = 0\n",
    "\t\n",
    "\tfor file, extractor, cost in dequeue_list:\n",
    "\n",
    "\t\tif count == threshold:\n",
    "\t\t\tbreak\n",
    "\n",
    "\n",
    "\t\tparsed_key = file.split(\"/\")\n",
    "\t\tfilename = parsed_key[len(parsed_key) - 1]\n",
    "\t\tif extractor == 'keyword': # keyword\n",
    "\t\t\tfilepath = '/home/cc/CDIACMetadataExtract/CDIACKeywordExtract/' + filename + 'KWXtract' + file_to_index_dict[file] + '.json'\n",
    "\t\t\tcompleteness_scores[file] = completeness_score_keyword(filepath)\t\t\t\n",
    "\t\telif extractor == 'tabular': # tabular\n",
    "\t\t\tfilepath = '/home/cc/CDIACMetadataExtract/CDIACTabularExtracted/' + filename +  'TabXtract' + file_to_index_dict[file] + '.json'\n",
    "\t\t\tcompleteness_scores[file] = completeness_score_tabular(filepath)\n",
    "\t\t#elif value == 3: # unknown\n",
    "\t\t#\tfilepath = '/home/cc/CDIACMetadataExtract/CDIACKeywordExtract/' + key + file_to_index_dict[key] + 'KWXtract.json'\n",
    "\t\telif extractor == 'json/xml': #json/xml\n",
    "\t\t\tfilepath = '/home/cc/CDIACMetadataExtract/CDIACJSONXMLExtracted/' + filename + 'JSONXMLXtract' + file_to_index_dict[file] + '.json'\n",
    "\t\t\tcompleteness_scores[file] = completeness_score_jsonxml(filepath)\n",
    "\t\telif extractor == 'netcdf': #netcdf\n",
    "\t\t\tfilepath = '/home/cc/CDIACMetadataExtract/CDIACNETCDFExtracted/' + filename + 'NetCDFXtract' + file_to_index_dict[file] + '.json'\n",
    "\t\t\tcompleteness_scores[file] = completeness_score_netcdf(filepath)\n",
    "\t\telif extractor == 'image':\n",
    "\t\t\tfilepath = '/home/cc/CDIACMetadataExtract/CDIACImgPredictions/' + filename + 'ImgXtract' + file_to_index_dict[file] + '.json'\n",
    "\t\t\tcompleteness_scores[file] = completeness_score_img(filepath)\n",
    "\t\telse:\n",
    "\t\t\tprint('Something went wrong: ', extractor)\n",
    "\n",
    "\t\tif file in file_count:\n",
    "\t\t\tfile_count[file] += 1\n",
    "\t\telse:\n",
    "\t\t\tfile_count[file] = 1\n",
    "\t\textractor_count[extractor] += 1\n",
    "\t\treadability_scores[filepath] = readability_score(filepath)\n",
    "\t\tif filepath in tfidf_precomputed:\n",
    "\t\t\ttfidf_scores[filepath] = tfidf_precomputed[filepath]\n",
    "\t\telse:\n",
    "\t\t\ttfidf_scores[filepath] = tfidf_score(filepath)\n",
    "\t\t\ttfidf_precomputed[filepath] = tfidf_scores[filepath]\n",
    "\t\t\t\n",
    "\t\tcost_scores[filepath] = cost\n",
    "\n",
    "\t\tcount += 1\n",
    "\n",
    "\treturn readability_scores, completeness_scores, tfidf_scores, cost_scores, extractor_count, file_count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experimentation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "with open(\"EstimateTime/file_to_index.json\", \"r\") as fp:\n",
    "\tfile_to_index_dict = json.load(fp)\n",
    "file_to_index_dict = dict(zip(file_to_index_dict.values(), file_to_index_dict.keys()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "X = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "Y_readability = []\n",
    "Y_completeness = []\n",
    "Y_tfidf = []\n",
    "\n",
    "readability_total = dict()\n",
    "completeness_total = dict()\n",
    "tfidf_total = dict()\n",
    "\n",
    "average_readability = []\n",
    "average_completeness = []\n",
    "average_tfidf = []\n",
    "\n",
    "extractor_counts = [] # list of dicts\n",
    "file_counts = [] # list of dicts \n",
    "\n",
    "\n",
    "tfidf_computed = dict() # Dynamic Programming Array to reduce computation redundancy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "with open('Experiment4/dequeue_list.pkl', 'rb') as fp:\n",
    "\tdequeue_list = pkl.load(fp)\n",
    "\tfor threshold in X:\n",
    "\t\tprint(\"Threshold: \", threshold)\n",
    "\t\tinput_threshold = threshold * len(dequeue_list)\n",
    "\n",
    "\t\treadability_scores, completeness_scores, tfidf_scores, cost_scores, extractor_count, file_count = get_metadata_metrics(dequeue_list, file_to_index_dict, tfidf_computed, input_threshold)\n",
    "\n",
    "\t\textractor_counts.append(extractor_count)\n",
    "\t\tfile_counts.append(file_count)\n",
    "\n",
    "\t\treadable_count = 0\n",
    "\t\treadable = []\n",
    "\t\tfor key, value in readability_scores.items():\n",
    "\t\t\tif value != 'no strings':\n",
    "\t\t\t\treadable_count += 1\n",
    "\t\t\t\treadable.append(value)\n",
    "\n",
    "\t\tY_readability.append(float(readable_count))\n",
    "\t\treadability_total[threshold] = readable\n",
    "\n",
    "\n",
    "\t\tif len(readable) == 0:\n",
    "\t\t\tavg_readability = 0\n",
    "\t\telse:\n",
    "\t\t\tavg_readability = sum(readable) / len(readable)\n",
    "\n",
    "\t\tprint(\"Readability: \", avg_readability)\n",
    "\t\taverage_readability.append(avg_readability)\n",
    "\n",
    "\t\tcomplete = 0\n",
    "\t\tcomplete_valid = []\n",
    "\n",
    "\t\tfor key, value in completeness_scores.items():\n",
    "\t\t\tif value != 0:\n",
    "\t\t\t\tcomplete += 1\n",
    "\t\t\t\tcomplete_valid.append(value)\n",
    "\t\t\n",
    "\t\tY_completeness.append(float(complete))\n",
    "\t\tcompleteness_total[threshold] = complete_valid\n",
    "\n",
    "\t\tif len(complete_valid) == 0:\n",
    "\t\t\tavg_completeness = 0\n",
    "\t\telse:\n",
    "\t\t\tavg_completeness = sum(complete_valid) / len(complete_valid)\n",
    "\n",
    "\t\tprint(\"Completeness\", avg_completeness)\n",
    "\t\taverage_completeness.append(avg_completeness)\n",
    "\n",
    "\t\tnonzero_tfidf = 0\n",
    "\t\ttfidf_valid = []\n",
    "\t\t\n",
    "\t\tfor key, value in tfidf_scores.items():\n",
    "\t\t\tif value != 0:\n",
    "\t\t\t\tnonzero_tfidf += 1\n",
    "\t\t\t\ttfidf_valid.append(value)\n",
    "\t\tY_tfidf.append(float(nonzero_tfidf))\n",
    "\t\ttfidf_total[threshold] = tfidf_valid\n",
    "\n",
    "\t\tif len(tfidf_valid) == 0:\n",
    "\t\t\tavg_tfidf = 0\n",
    "\t\telse:\n",
    "\t\t\tavg_tfidf = sum(tfidf_valid) / len(tfidf_valid)\n",
    "\n",
    "\t\tprint(\"TFIDF\", avg_tfidf)\n",
    "\t\taverage_tfidf.append(avg_tfidf)\n",
    "\n",
    "\t\tprint(\"Precomputed length: \", len(tfidf_computed))\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Threshold:  0\n",
      "Readability:  0\n",
      "Completeness 0\n",
      "TFIDF 0\n",
      "Precomputed length:  0\n",
      "Threshold:  0.1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(X))\n",
    "print(len(Y_readability))\n",
    "print(len(Y_completeness))\n",
    "print(len(Y_tfidf))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = np.asarray(X)\n",
    "Y_readability = np.asarray(Y_readability)[0:]\n",
    "Y_completeness = np.asarray(Y_completeness)[0:]\n",
    "Y_tfidf = np.asarray(Y_tfidf)[0:]\n",
    "\n",
    "print(len(Y_readability))\n",
    "\n",
    "plt.title(\"Percent Extracted v. Readability\")\n",
    "plt.xlabel(\"Percent Extracted\")\n",
    "plt.ylabel(\"Readable files\")\n",
    "plt.scatter(X, Y_readability)\n",
    "plt.plot(X, Y_readability)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Percent Extracted v. Completeness\")\n",
    "plt.xlabel(\"Percent Extracted\")\n",
    "plt.ylabel(\"Somewhat complete files\")\n",
    "plt.scatter(X, Y_completeness)\n",
    "plt.plot(X, Y_completeness)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Percent Extracted v. TFIDF\")\n",
    "plt.xlabel(\"Percent Extracted\")\n",
    "plt.ylabel(\"Nonzero TFIDF files\")\n",
    "plt.scatter(X, Y_tfidf)\n",
    "plt.plot(X, Y_tfidf)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Reward of file over time\")\n",
    "plt.xlabel(\"File Order Index\")\n",
    "plt.ylabel(\"Cost in bytes/sec\")\n",
    "plt.plot(range(0, len(cost_scores)), list(cost_scores.values()))\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Processing of average readability"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "average_readability = np.array(average_readability)\n",
    "average_readability = average_readability / np.max(average_readability)\n",
    "print(average_readability)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Processing of average completeness"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(completeness_total['0.1'])\n",
    "\n",
    "cum_completeness = np.zeros(len(completeness_total))\n",
    "\n",
    "for idx, key in enumerate(completeness_total):\n",
    "\tcum_completeness[idx] = np.sum(np.array(completeness_total[key]))\n",
    "\n",
    "print(cum_completeness)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.scatter(X, average_readability)\n",
    "plt.plot(X, average_readability)\n",
    "plt.xlabel(\"File Extractor Pairs Processed\")\n",
    "plt.ylabel(\"Average Readability (Normalized)\")\n",
    "plt.title(\"File Extractor Pairs Processed vs Avg Readability\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X, cum_completeness)\n",
    "plt.plot(X, cum_completeness)\n",
    "plt.xlabel(\"File Extractor Pairs Processed\")\n",
    "plt.ylabel(\"Cumulative Completeness\")\n",
    "plt.title(\"File Extractor Pairs Processed vs Cumulative Completeness\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X, average_tfidf)\n",
    "plt.plot(X, average_tfidf)\n",
    "plt.xlabel(\"Percent Extracted\")\n",
    "plt.ylabel(\"Average TFIDF\")\n",
    "plt.title(\"Percent Extracted vs Avg TFIDF\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(extractor_counts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "keyword_count = []\n",
    "tabular_count = []\n",
    "jsonxml_count = []\n",
    "netcdf_count = []\n",
    "image_count = []\n",
    "\n",
    "file_count_list = []\n",
    "\n",
    "for dictionary in extractor_counts:\n",
    "\tfor key, value in dictionary.items():\n",
    "\t\tif key == \"keyword\":\n",
    "\t\t\tkeyword_count.append(value)\n",
    "\t\telif key == \"tabular\":\n",
    "\t\t\ttabular_count.append(value)\n",
    "\t\telif key == \"netcdf\":\n",
    "\t\t\tnetcdf_count.append(value)\n",
    "\t\telif key == \"json/xml\":\n",
    "\t\t\tjsonxml_count.append(value)\n",
    "\t\telif key == \"image\":\n",
    "\t\t\timage_count.append(value)\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Something went wrong\")\n",
    "\n",
    "for fc in file_counts:\n",
    "\tfile_count_list.append(len(list(fc.keys())))\n",
    "\t"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(keyword_count)\n",
    "print(tabular_count)\n",
    "print(jsonxml_count)\n",
    "print(netcdf_count)\n",
    "print(image_count)\n",
    "print(file_count_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(X, keyword_count, label=\"Keyword Extractions\")\n",
    "plt.plot(X, tabular_count, label=\"Tabular Extractions\")\n",
    "plt.plot(X, jsonxml_count, label=\"JSON/XML Extractions\")\n",
    "plt.plot(X, netcdf_count, label=\"NetCDF Extractions\")\n",
    "plt.plot(X, image_count, label=\"Image Extractions\")\n",
    "plt.plot(X, file_count_list, label=\"Unique Files extracted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels, data = [*zip(*readability_total.items())]  # 'transpose' items to parallel key, value lists\n",
    "#for d in data:\n",
    "\t#print(d)\n",
    "\n",
    "plt.boxplot(data, whis=[5, 95])\n",
    "plt.xticks(range(1, len(labels) + 1), labels)\n",
    "plt.title(\"Box and Whisker plots of Percent Extract vs. Readability Scores\")\n",
    "plt.xlabel(\"Percent Extracted\")\n",
    "plt.ylabel(\"Readability Score\")\n",
    "plt.show()\n",
    "\n",
    "labels, data = [*zip(*completeness_total.items())]  # 'transpose' items to parallel key, value lists\n",
    "plt.boxplot(data)\n",
    "plt.xticks(range(1, len(labels) + 1), labels)\n",
    "plt.xlabel(\"Percent Extracted\")\n",
    "plt.ylabel(\"Completeness Score\")\n",
    "plt.title(\"Box and Whisker plots of Percent Extract vs. Completeness Scores\")\n",
    "plt.show()\n",
    "\n",
    "labels, data = [*zip(*tfidf_total.items())]  # 'transpose' items to parallel key, value lists\n",
    "plt.boxplot(data)\n",
    "plt.xticks(range(1, len(labels) + 1), labels)\n",
    "plt.xlabel(\"Percent Extracted\")\n",
    "plt.ylabel(\"TFIDF Score\")\n",
    "plt.title(\"Box and Whisker plots of Percent Extract vs. TFIDF Scores\")\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Threshold = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "Time = [0, 192.54913187026978, 201.7842311859131, 287.3370723724365, 437.8477611541748,  585.3103694915771, 591.996896982193, 598.9227044582367, 606.2875552177429, 614.1233706474304, 967.380571603775]\n",
    "plt.plot(Threshold, Time)\n",
    "plt.xlabel(\"threshold\")\n",
    "plt.ylabel(\"time\")\n",
    "plt.title(\"threshold vs time\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}